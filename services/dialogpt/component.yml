dialogpt:
  name: dialogpt
  display_name: DialoGPT
  container_name: dialogpt
  component_type: Generative
  model_type: NN-based
  is_customizable: false
  author: publisher@deeppavlov.ai
  description: generative service based on Transformers generative model, the model
    is set in docker compose argument `PRETRAINED_MODEL_NAME_OR_PATH` (for example,
    `microsoft/DialoGPT-small` with 0.2-0.5 sec on GPU)
  ram_usage: 1.2G
  gpu_usage: 2.1G
  port: 8125
  endpoints:
  - group: skills
    endpoint: respond
  - group: services
    endpoint: continue
  build_args:
    SERVICE_PORT: 8125
    SERVICE_NAME: dialogpt
    PRETRAINED_MODEL_NAME_OR_PATH: microsoft/DialoGPT-medium
    N_HYPOTHESES_TO_GENERATE: 5
    CONFIG_NAME: dialogpt_en.json
    MAX_HISTORY_DEPTH: 2
  date_created: '2023-03-16T09:45:32'
  compose_override:
    env_file:
    - .env
    build:
      args:
        SERVICE_PORT: 8125
        SERVICE_NAME: dialogpt
        PRETRAINED_MODEL_NAME_OR_PATH: microsoft/DialoGPT-medium
        N_HYPOTHESES_TO_GENERATE: 5
        CONFIG_NAME: dialogpt_en.json
        MAX_HISTORY_DEPTH: 2
      context: .
      dockerfile: ./services/dialogpt/Dockerfile
    command: flask run -h 0.0.0.0 -p 8125
    environment:
    - CUDA_VISIBLE_DEVICES=0
    - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 2G
  compose_dev:
    volumes:
    - ./services/dialogpt:/src
    - ./common:/src/common
    - ~/.deeppavlov/cache:/root/.cache
    ports:
    - 8125:8125
  compose_proxy:
    command:
    - nginx
    - -g
    - daemon off;
    build:
      context: dp/proxy/
      dockerfile: Dockerfile
    environment:
    - PROXY_PASS=dream.deeppavlov.ai:8125
    - PORT=8125
