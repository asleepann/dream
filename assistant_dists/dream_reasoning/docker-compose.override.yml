services:
  agent:
    command: sh -c 'bin/wait && python -m deeppavlov_agent.run agent.pipeline_config=assistant_dists/dream_reasoning/pipeline_conf.json'
    environment:
      WAIT_HOSTS: "convers-evaluator-annotator:8004,
          sentseg:8011, convers-evaluation-selector:8009, badlisted-words:8018,
          spelling-preprocessing:8074, combined-classification:8087,
          openai-api-chatgpt:8145, dff-reasoning-skill:8162"
      WAIT_HOSTS_TIMEOUT: ${WAIT_TIMEOUT:-480}
      HIGH_PRIORITY_INTENTS: 1
      RESTRICTION_FOR_SENSITIVE_CASE: 1
      ALWAYS_TURN_ON_ALL_SKILLS: 0
      LANGUAGE: EN

  convers-evaluator-annotator:
    env_file: [ .env ]
    build:
      args:
        CONFIG: conveval.json
        SERVICE_PORT: 8004
        DATA_URL: https://files.deeppavlov.ai/alexaprize_data/cobot_conveval2.tar.gz
      context: .
      dockerfile: ./annotators/ConversationEvaluator/Dockerfile
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 2G

  sentseg:
    env_file: [ .env ]
    build:
      context: ./annotators/SentSeg/
    command: flask run -h 0.0.0.0 -p 8011
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 1.5G
        reservations:
          memory: 1.5G

  convers-evaluation-selector:
    env_file: [ .env ]
    build:
      args:
        TAG_BASED_SELECTION: 1
        CALL_BY_NAME_PROBABILITY: 0.5
        PROMPT_PROBA: 0.1
        ACKNOWLEDGEMENT_PROBA: 0.3
        PRIORITIZE_WITH_REQUIRED_ACT: 0
        PRIORITIZE_NO_DIALOG_BREAKDOWN: 0
        PRIORITIZE_WITH_SAME_TOPIC_ENTITY: 0
        IGNORE_DISLIKED_SKILLS: 0
        GREETING_FIRST: 1
        RESTRICTION_FOR_SENSITIVE_CASE: 1
        PRIORITIZE_PROMTS_WHEN_NO_SCRIPTS: 1
        MAX_TURNS_WITHOUT_SCRIPTS: 7
        ADD_ACKNOWLEDGMENTS_IF_POSSIBLE: 1
        PRIORITIZE_SCRIPTED_SKILLS: 0
        CONFIDENCE_STRENGTH: 0.8
        CONV_EVAL_STRENGTH: 0.4
        PRIORITIZE_HUMAN_INITIATIVE: 1
        QUESTION_TO_QUESTION_DOWNSCORE_COEF: 0.8
        LANGUAGE: EN
      context: .
      dockerfile: ./response_selectors/convers_evaluation_based_selector/Dockerfile
    command: flask run -h 0.0.0.0 -p 8009
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 100M
        reservations:
          memory: 100M

  badlisted-words:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8018
        SERVICE_NAME: badlisted_words
      context: annotators/BadlistedWordsDetector/
    command: flask run -h 0.0.0.0 -p 8018
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  spelling-preprocessing:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8074
        SERVICE_NAME: spelling_preprocessing
      context: ./annotators/spelling_preprocessing/
    command: flask run -h 0.0.0.0 -p 8074
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 100M
        reservations:
          memory: 100M

  combined-classification:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8087
        SERVICE_NAME: combined_classification
        CONFIG: combined_classifier.json
      context: .
      dockerfile: ./annotators/combined_classification/Dockerfile
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 2G

  openai-api-chatgpt:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8145
        SERVICE_NAME: openai_api_chatgpt
        PRETRAINED_MODEL_NAME_OR_PATH: gpt-3.5-turbo
      context: .
      dockerfile: ./services/openai_api_lm/Dockerfile
    command: flask run -h 0.0.0.0 -p 8145
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 100M
        reservations:
          memory: 100M

  # goal-detector:
  #   env_file: [ .env,.env_secret ]
  #   build:
  #     args:
  #       SERVICE_PORT: 8163
  #       SERVICE_NAME: goal_detector
  #       GENERATIVE_SERVICE_URL: http://openai-api-chatgpt:8145/respond
  #       GENERATIVE_SERVICE_CONFIG: generative_configs/openai-chatgpt.json
  #       GENERATIVE_TIMEOUT: 30
  #       ENVVARS_TO_SEND: OPENAI_API_KEY,OPENAI_ORGANIZATION,GOOGLE_CSE_ID,GOOGLE_API_KEY
  #     context: ./annotators/goal_detector/
  #   command: flask run -h 0.0.0.0 -p 8163
  #   environment:
  #     - FLASK_APP=server
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 100M
  #       reservations:
  #         memory: 100M
  
  # transformers-lm-gptjt:
  #   env_file: [ .env ]
  #   build:
  #     args:
  #       SERVICE_PORT: 8161
  #       SERVICE_NAME: transformers_lm_gptjt
  #       PRETRAINED_MODEL_NAME_OR_PATH: togethercomputer/GPT-JT-6B-v1
  #       HALF_PRECISION: 0
  #     context: .
  #     dockerfile: ./services/transformers_lm/Dockerfile
  #   command: flask run -h 0.0.0.0 -p 8161
  #   environment:
  #     - CUDA_VISIBLE_DEVICES=0
  #     - FLASK_APP=server
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 50G
  #       reservations:
  #         memory: 50G

  # dff-dream-persona-gpt-jt-prompted-skill:
  #   env_file: [ .env ]
  #   build:
  #     args:
  #       SERVICE_PORT: 8134
  #       SERVICE_NAME: dff_dream_persona_prompted_skill
  #       PROMPT_FILE: common/prompts/dream_persona.json
  #       GENERATIVE_SERVICE_URL: http://transformers-lm-gptjt:8161/respond
  #       GENERATIVE_SERVICE_CONFIG: default_generative_config.json
  #       GENERATIVE_TIMEOUT: 120
  #       N_UTTERANCES_CONTEXT: 7
  #     context: .
  #     dockerfile: ./skills/dff_template_prompted_skill/Dockerfile
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 128M
  #       reservations:
  #         memory: 128M

  dff-reasoning-skill:
    env_file: [ .env,.env_secret ]
    build:
      args:
        SERVICE_PORT: 8162
        SERVICE_NAME: dff_reasoning_skill
        GENERATIVE_SERVICE_URL: http://openai-api-chatgpt:8145/respond
        GENERATIVE_SERVICE_CONFIG: generative_configs/openai-chatgpt.json
        GENERATIVE_TIMEOUT: 15
        N_UTTERANCES_CONTEXT: 1
        ENVVARS_TO_SEND: OPENAI_API_KEY,GOOGLE_CSE_ID,GOOGLE_API_KEY,OPENWEATHERMAP_API_KEY,NEWS_API_KEY
      context: .
      dockerfile: ./skills/dff_reasoning_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8162 --reload
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M
version: '3.7'