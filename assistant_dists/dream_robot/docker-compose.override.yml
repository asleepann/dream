services:
  agent:
    command: sh -c 'bin/wait && python -m deeppavlov_agent.run agent.pipeline_config=assistant_dists/dream_robot/pipeline_conf.json'
    environment:
      WAIT_HOSTS: "convers-evaluator-annotator:8004, dff-program-y-skill:8008, sentseg:8011, convers-evaluation-selector:8009, 
          dff-intent-responder-skill:8012, intent-catcher:8014, badlisted-words:8018,
          spelling-preprocessing:8074, dialogpt:8125, entity-detection:8103, ner:8021, robot:8130,
          dff-command-selector-skill:8015"
      WAIT_HOSTS_TIMEOUT: ${WAIT_TIMEOUT:-480}
  convers-evaluator-annotator:
    env_file: [.env]
    build:
      args:
        CONFIG: conveval.json
        PORT: 8004
        DATA_URL: https://files.deeppavlov.ai/alexaprize_data/cobot_conveval2.tar.gz
      context: .
      dockerfile: ./annotators/ConversationEvaluator/Dockerfile
    environment:
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      mode: replicated
      replicas: 1
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 2G

  dff-program-y-skill:
    env_file: [.env]
    build:
      args:
        SERVICE_PORT: 8008
        SERVICE_NAME: dff_program_y_skill
        LANGUAGE: EN
      context: .
      dockerfile: ./skills/dff_program_y_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8008 --reload
    deploy:
      resources:
        limits:
          memory: 1024M
        reservations:
          memory: 1024M


  sentseg:
    env_file: [.env]
    build:
      context: ./annotators/SentSeg/
    command: flask run -h 0.0.0.0 -p 8011
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 1.5G
        reservations:
          memory: 1.5G

  convers-evaluation-selector:
    env_file: [.env]
    build:
      args:
        TAG_BASED_SELECTION: 1
        CALL_BY_NAME_PROBABILITY: 0
        PROMPT_PROBA: 0
        ACKNOWLEDGEMENT_PROBA: 0
        PRIORITIZE_WITH_REQUIRED_ACT: 0
        PRIORITIZE_NO_DIALOG_BREAKDOWN: 0
        PRIORITIZE_WITH_SAME_TOPIC_ENTITY: 0
        IGNORE_DISLIKED_SKILLS: 0
        GREETING_FIRST: 1
        RESTRICTION_FOR_SENSITIVE_CASE: 1
        PRIORITIZE_PROMTS_WHEN_NO_SCRIPTS: 0
        ADD_ACKNOWLEDGMENTS_IF_POSSIBLE: 0
        PRIORITIZE_SCRIPTED_SKILLS: 0
      context: .
      dockerfile: ./response_selectors/convers_evaluation_based_selector/Dockerfile
    command: flask run -h 0.0.0.0 -p 8009
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  dff-intent-responder-skill:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8012
        SERVICE_NAME: dff_intent_responder_skill
        INTENT_RESPONSE_PHRASES_FNAME: intent_response_phrases_robot.json
      context: .
      dockerfile: ./skills/dff_intent_responder_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8012 --reload
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  dff-command-selector-skill:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8012
        SERVICE_NAME: dff_command_selector_skill
        LANGUAGE: RU
        ROS_FSM_SERVER: http://robot-fake-server:8137
      context: .
      dockerfile: ./skills/dff_command_selector_skill/Dockerfile
    command: gunicorn --workers=1 server:app -b 0.0.0.0:8015 --reload
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

  intent-catcher:
    env_file: [.env]
    build:
      context: .
      dockerfile: ./annotators/IntentCatcherTransformers/Dockerfile
      args:
        SERVICE_PORT: 8014
        CONFIG_NAME: robot_intents_model_dp_config.json
        INTENT_PHRASES_PATH: robot_intent_phrases.json
    command:  python -m flask run -h 0.0.0.0 -p 8014
    environment:
      - FLASK_APP=server
      - CUDA_VISIBLE_DEVICES=0
    deploy:
      resources:
        limits:
          memory: 3.5G
        reservations:
          memory: 3.5G

  badlisted-words:
    env_file: [.env]
    build:
      context: annotators/BadlistedWordsDetector/
    command: flask run -h 0.0.0.0 -p 8018
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 256M

  spelling-preprocessing:
    env_file: [.env]
    build:
      context: ./annotators/spelling_preprocessing/
    command: flask run -h 0.0.0.0 -p 8074
    environment:
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 50M
        reservations:
          memory: 50M

  dialogpt:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8125
        SERVICE_NAME: dialogpt
        PRETRAINED_MODEL_NAME_OR_PATH: microsoft/DialoGPT-medium
        N_HYPOTHESES_TO_GENERATE: 5
      context: ./services/dialogpt/
    command: flask run -h 0.0.0.0 -p 8125
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - FLASK_APP=server
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 2G

  entity-detection:
    env_file: [.env]
    build:
      args:
        SEQ_TAG_CONFIG: src/wikipedia_entity_detection_distilbert.json
        EL_TAG_CONFIG: src/el_tags_infer.json
        CONFIG: entity_detection_eng.json
        LOWERCASE: 1
        PORT: 8103
        SRC_DIR: annotators/entity_detection/
        FINEGRAINED: 0
      context: ./
      dockerfile: annotators/entity_detection/Dockerfile
    command: flask run -h 0.0.0.0 -p 8103
    environment:
      - FLASK_APP=server
      - CUDA_VISIBLE_DEVICES=7
    deploy:
      resources:
        limits:
          memory: 2.5G
        reservations:
          memory: 2.5G

  ner:
    env_file: [.env]
    build:
      context: ./annotators/NER/
    command: flask run -h 0.0.0.0 -p 8021
    environment:
      - FLASK_APP=server
    tty: true
    deploy:
      resources:
        limits:
          memory: 1512M
        reservations:
          memory: 1512M

  robot:
    env_file: [ .env ]
    build:
      args:
        SERVICE_PORT: 8130
      context: .
      dockerfile: ./skills/robot_skill/Dockerfile
    command: uvicorn --workers=1 server:app --host 0.0.0.0 --port 8130 --reload
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 128M

version: '3.7'
