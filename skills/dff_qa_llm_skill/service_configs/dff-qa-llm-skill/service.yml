name: dff-qa-llm-skill
endpoints:
- respond
compose:
  env_file:
  - .env
  build:
    args:
      SERVICE_PORT: 8164
      SERVICE_NAME: dff_qa_llm_skill
      GENERATIVE_SERVICE_URL: http://openai-api-chatgpt:8145/respond
      GENERATIVE_SERVICE_CONFIG: openai-chatgpt.json
      GENERATIVE_TIMEOUT: 120
      N_UTTERANCES_CONTEXT: 7
    context: .
    dockerfile: ./skills/dff_qa_llm_skill/Dockerfile
  command: gunicorn --workers=1 server:app -b 0.0.0.0:8164 --reload
  deploy:
    resources:
      limits:
        memory: 128M
      reservations:
        memory: 128M
  volumes:
  - ./skills/dff_qa_llm_skill:/src
  - ./common:/src/common
  ports:
  - 8164:8164
proxy:
  command:
  - nginx
  - -g
  - daemon off;
  build:
    context: dp/proxy/
    dockerfile: Dockerfile
  environment:
  - PROXY_PASS=dream.deeppavlov.ai:8164
  - PORT=8164
